{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewright17/Homework-1-Deep-Learning/blob/problem-1.2-actual-task/MNIST_train_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJGxUuyzp5Bn"
      },
      "source": [
        "# Homework 1-1 Part 2\n",
        "\n",
        "## Train on Actual Tasks\n",
        "\n",
        "In this notebook we will be training a CNN on the MNIST data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOFgPbtkp5Bq"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9owBvBlPp5Bq"
      },
      "outputs": [],
      "source": [
        "### Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBNpVe7Up5Br"
      },
      "source": [
        "### Specify GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-WNL36Np5Bs",
        "outputId": "3077e1d8-175c-42cb-ad1c-927d2f4a2b18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device cuda\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15EHoyMBp5Bs"
      },
      "source": [
        "### Model Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eSrt7z00p5Bs"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "#input_size = 784  # 28x28 flattened images\n",
        "num_classes = 10\n",
        "num_epochs = 50\n",
        "batch_size = 64\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eC6iMzRjp5Bs"
      },
      "source": [
        "### Load MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g647Tpl5p5Bt",
        "outputId": "1ff85e6e-93a8-4322-c638-20a6c9a1863c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 344169795.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 5803741.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 194567207.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3273286.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Data loaders\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9AL0HQep5Bt"
      },
      "source": [
        "### View Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "_1tVkJpMp5Bt",
        "outputId": "99570506-819e-447a-b5ed-362513465f7a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Choose an image index\n",
        "image_index = 5  # You can change this to any valid index\n",
        "\n",
        "# Get the image and label\n",
        "image, label = train_dataset[image_index]\n",
        "\n",
        "# Convert the image tensor to a numpy array\n",
        "image_array = image.numpy()\n",
        "\n",
        "# Reshape the array to 28x28\n",
        "image_array = image_array.reshape(28, 28)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image_array, cmap='gray')\n",
        "plt.title(f\"Label: {label}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cJajbBNp5Bu"
      },
      "source": [
        "### Define CNN Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xPD1zKTPp5Bu"
      },
      "outputs": [],
      "source": [
        "# CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes, out_channels_1, out_channels_2):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=out_channels_1, kernel_size=3, padding=1),\n",
        "                                   nn.MaxPool2d(kernel_size=2),\n",
        "                                   nn.ReLU())\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(in_channels=out_channels_1, out_channels=out_channels_2,\n",
        "                                             kernel_size=3, padding=1),\n",
        "                                   nn.MaxPool2d(kernel_size=2),\n",
        "                                   nn.ReLU())\n",
        "        self.fc = nn.Linear(out_channels_2 * 7 * 7, num_classes)  # Assuming input images are 28x28\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "       x = self.conv1(x)\n",
        "       x = self.conv2(x)\n",
        "       x = x.view(x.size(0), -1)\n",
        "       x = self.fc(x)\n",
        "       return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0W16y0vp5Bu"
      },
      "source": [
        "### Assign Model, Loss, and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Sk8K-x8Vp5Bv"
      },
      "outputs": [],
      "source": [
        "CNN_1 = CNN(num_classes=num_classes, out_channels_1=16, out_channels_2=32).to(device)\n",
        "CNN_2 = CNN(num_classes=num_classes, out_channels_1=8, out_channels_2=16).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f0nr-3ip5Bv"
      },
      "source": [
        "### Train Model and Evaluate Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DtpaPyKap5Bv"
      },
      "outputs": [],
      "source": [
        "### training function\n",
        "def train_eval(model, num_epochs, learning_rate, train_loader, test_loader):\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    # Training loop\n",
        "    total_loss = []\n",
        "    total_accuracy = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0.0\n",
        "\n",
        "        #Training\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zero out Gradient and get checkpoints (memory efficiency)\n",
        "            checkpoint_inputs = torch.utils.checkpoint.checkpoint(model, images)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(checkpoint_inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss * images.size(0)\n",
        "\n",
        "        train_loss = train_loss/len(train_loader.sampler)\n",
        "        total_loss.append(train_loss)\n",
        "        print(f\"train loss: {train_loss}\")\n",
        "\n",
        "        #Validation\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "        total_accuracy.append(accuracy)\n",
        "        print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "    return total_loss, total_accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cBAOe-NGLWr1",
        "outputId": "38b5b61c-93a9-4a92-c470-d2bb8d3d8525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss: 0.2557739317417145\n",
            "Accuracy of the network on the 10000 test images: 97.68 %\n",
            "train loss: 0.07508731633424759\n",
            "Accuracy of the network on the 10000 test images: 98.41 %\n",
            "train loss: 0.05661168694496155\n",
            "Accuracy of the network on the 10000 test images: 98.63 %\n",
            "train loss: 0.04549906775355339\n",
            "Accuracy of the network on the 10000 test images: 98.64 %\n",
            "train loss: 0.038777995854616165\n",
            "Accuracy of the network on the 10000 test images: 98.78 %\n",
            "train loss: 0.032905738800764084\n",
            "Accuracy of the network on the 10000 test images: 98.9 %\n",
            "train loss: 0.02900022454559803\n",
            "Accuracy of the network on the 10000 test images: 98.85 %\n",
            "train loss: 0.025629807263612747\n",
            "Accuracy of the network on the 10000 test images: 98.76 %\n",
            "train loss: 0.02310141921043396\n",
            "Accuracy of the network on the 10000 test images: 98.92 %\n",
            "train loss: 0.020462727174162865\n",
            "Accuracy of the network on the 10000 test images: 98.91 %\n",
            "train loss: 0.017733419314026833\n",
            "Accuracy of the network on the 10000 test images: 98.77 %\n",
            "train loss: 0.01576768048107624\n",
            "Accuracy of the network on the 10000 test images: 98.72 %\n",
            "train loss: 0.013886184431612492\n",
            "Accuracy of the network on the 10000 test images: 98.83 %\n",
            "train loss: 0.012260178104043007\n",
            "Accuracy of the network on the 10000 test images: 98.89 %\n",
            "train loss: 0.011834058910608292\n",
            "Accuracy of the network on the 10000 test images: 98.73 %\n",
            "train loss: 0.010253416374325752\n",
            "Accuracy of the network on the 10000 test images: 98.73 %\n",
            "train loss: 0.009180343709886074\n",
            "Accuracy of the network on the 10000 test images: 98.74 %\n",
            "train loss: 0.009018803015351295\n",
            "Accuracy of the network on the 10000 test images: 99.03 %\n",
            "train loss: 0.007218690123409033\n",
            "Accuracy of the network on the 10000 test images: 98.95 %\n",
            "train loss: 0.006723491009324789\n",
            "Accuracy of the network on the 10000 test images: 98.79 %\n",
            "train loss: 0.007451471872627735\n",
            "Accuracy of the network on the 10000 test images: 98.76 %\n",
            "train loss: 0.006033129058778286\n",
            "Accuracy of the network on the 10000 test images: 98.95 %\n",
            "train loss: 0.0061490498483181\n",
            "Accuracy of the network on the 10000 test images: 98.89 %\n",
            "train loss: 0.004643129650503397\n",
            "Accuracy of the network on the 10000 test images: 98.89 %\n",
            "train loss: 0.005438217427581549\n",
            "Accuracy of the network on the 10000 test images: 98.81 %\n",
            "train loss: 0.004625100642442703\n",
            "Accuracy of the network on the 10000 test images: 98.9 %\n",
            "train loss: 0.004319360945373774\n",
            "Accuracy of the network on the 10000 test images: 98.85 %\n",
            "train loss: 0.002632319927215576\n",
            "Accuracy of the network on the 10000 test images: 98.89 %\n",
            "train loss: 0.004521999042481184\n",
            "Accuracy of the network on the 10000 test images: 98.6 %\n",
            "train loss: 0.005147772375494242\n",
            "Accuracy of the network on the 10000 test images: 98.91 %\n",
            "train loss: 0.002269508084282279\n",
            "Accuracy of the network on the 10000 test images: 98.82 %\n",
            "train loss: 0.0035134819336235523\n",
            "Accuracy of the network on the 10000 test images: 98.79 %\n",
            "train loss: 0.003173324977979064\n",
            "Accuracy of the network on the 10000 test images: 98.75 %\n",
            "train loss: 0.00236581452190876\n",
            "Accuracy of the network on the 10000 test images: 98.91 %\n",
            "train loss: 0.004302018787711859\n",
            "Accuracy of the network on the 10000 test images: 98.77 %\n",
            "train loss: 0.002156458329409361\n",
            "Accuracy of the network on the 10000 test images: 98.79 %\n",
            "train loss: 0.003039616858586669\n",
            "Accuracy of the network on the 10000 test images: 98.79 %\n",
            "train loss: 0.001960116671398282\n",
            "Accuracy of the network on the 10000 test images: 98.95 %\n",
            "train loss: 0.0028836997225880623\n",
            "Accuracy of the network on the 10000 test images: 98.77 %\n",
            "train loss: 0.0038169315084815025\n",
            "Accuracy of the network on the 10000 test images: 98.87 %\n",
            "train loss: 0.002162040676921606\n",
            "Accuracy of the network on the 10000 test images: 98.84 %\n",
            "train loss: 0.0020970439072698355\n",
            "Accuracy of the network on the 10000 test images: 98.75 %\n",
            "train loss: 0.002480691997334361\n",
            "Accuracy of the network on the 10000 test images: 98.86 %\n",
            "train loss: 0.0022471260745078325\n",
            "Accuracy of the network on the 10000 test images: 98.64 %\n",
            "train loss: 0.0024069035425782204\n",
            "Accuracy of the network on the 10000 test images: 98.86 %\n",
            "train loss: 0.0025248390156775713\n",
            "Accuracy of the network on the 10000 test images: 98.87 %\n",
            "train loss: 0.0017750838305801153\n",
            "Accuracy of the network on the 10000 test images: 98.83 %\n",
            "train loss: 0.004545209929347038\n",
            "Accuracy of the network on the 10000 test images: 98.9 %\n",
            "train loss: 0.0015824846923351288\n",
            "Accuracy of the network on the 10000 test images: 98.89 %\n",
            "train loss: 0.000922857376281172\n",
            "Accuracy of the network on the 10000 test images: 98.89 %\n",
            "train loss: 0.3286503851413727\n",
            "Accuracy of the network on the 10000 test images: 96.98 %\n",
            "train loss: 0.0879601389169693\n",
            "Accuracy of the network on the 10000 test images: 98.0 %\n",
            "train loss: 0.06570666283369064\n",
            "Accuracy of the network on the 10000 test images: 98.48 %\n",
            "train loss: 0.055136702954769135\n",
            "Accuracy of the network on the 10000 test images: 98.52 %\n",
            "train loss: 0.048097576946020126\n",
            "Accuracy of the network on the 10000 test images: 98.37 %\n",
            "train loss: 0.04236927255988121\n",
            "Accuracy of the network on the 10000 test images: 98.5 %\n",
            "train loss: 0.03959444910287857\n",
            "Accuracy of the network on the 10000 test images: 98.69 %\n",
            "train loss: 0.035027917474508286\n",
            "Accuracy of the network on the 10000 test images: 98.58 %\n",
            "train loss: 0.03258553519845009\n",
            "Accuracy of the network on the 10000 test images: 98.79 %\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2deaa7b9ce50>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m CNN_1_loss, CNN_1_accuracy = train_eval(model = CNN_1, num_epochs=num_epochs, learning_rate=learning_rate,\n\u001b[1;32m      3\u001b[0m                                         train_loader=train_loader, test_loader=test_loader)\n\u001b[0;32m----> 4\u001b[0;31m CNN_2_loss, CNN_2_accuracy = train_eval(model = CNN_2, num_epochs=num_epochs, learning_rate=learning_rate,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                         train_loader=train_loader, test_loader=test_loader)\n",
            "\u001b[0;32m<ipython-input-8-3e26c31ed51d>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(model, num_epochs, learning_rate, train_loader, test_loader)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "### Train models\n",
        "CNN_1_loss, CNN_1_accuracy = train_eval(model = CNN_1, num_epochs=num_epochs, learning_rate=learning_rate,\n",
        "                                        train_loader=train_loader, test_loader=test_loader)\n",
        "CNN_2_loss, CNN_2_accuracy = train_eval(model = CNN_2, num_epochs=num_epochs, learning_rate=learning_rate,\n",
        "                                        train_loader=train_loader, test_loader=test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gdtwq-c7p5Bv"
      },
      "source": [
        "### Plot Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rTmOjRqp5Bw"
      },
      "outputs": [],
      "source": [
        "# Loss Plot\n",
        "CNN_1_loss = torch.tensor(CNN_1_loss).cpu().data.numpy()\n",
        "CNN_2_loss = torch.tensor(CNN_2_loss).cpu().data.numpy()\n",
        "plt.plot(np.arange(0, len(CNN_1_loss), 1), CNN_1_loss, label = \"CNN_1 Loss\", color = \"blue\")\n",
        "plt.plot(np.arange(0, len(CNN_1_loss), 1), CNN_2_loss, label = \"CNN_2 Loss\", color = \"orange\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Accuracy Plot\n",
        "plt.plot(np.arange(0, len(CNN_1_accuracy), 1), np.array(CNN_1_accuracy), label = \"CNN_1 Accuracy\", color = \"blue\")\n",
        "plt.plot(np.arange(0, len(CNN_1_accuracy), 1), np.array(CNN_2_accuracy), label = \"CNN_2 Accuracy\", color = \"orange\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}